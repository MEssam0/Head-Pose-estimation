{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and fature extraction\n",
        "below you will see that we load data with three techniques each of them will work with one of the three models"
      ],
      "metadata": {
        "id": "1_G_10RdlcdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data from Kaggle"
      ],
      "metadata": {
        "id": "SWXjQqcnUMhu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Zrbk9n47VgEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368f98db-5c86-4c72-8243-4c9413ae4507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle \n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kameo4189/aflw2000-300wlp"
      ],
      "metadata": {
        "id": "hrJR-AGlWBfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f6e206-2567-402d-a31a-4c36cf36debf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading aflw2000-300wlp.zip to /content\n",
            "100% 3.65G/3.65G [00:35<00:00, 110MB/s]\n",
            "100% 3.65G/3.65G [00:35<00:00, 111MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "_j4A54nEWZpn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os,cv2,math,glob,random\n",
        "import scipy.io as sio\n",
        "from math import cos, sin\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import mediapipe\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob"
      ],
      "metadata": {
        "id": "EVVtaO5EWYsi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/aflw2000-300wlp.zip"
      ],
      "metadata": {
        "id": "nfcCdru7WKWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(load_type='whole'):\n",
        "  data = dict()\n",
        "  faceModule = mediapipe.solutions.face_mesh\n",
        "  with faceModule.FaceMesh(static_image_mode=True) as faces:\n",
        "    for img in glob.glob(\"/content/AFLW2000-3D/AFLW2000/*.jpg\"):\n",
        "        # loading the image\n",
        "        image = cv2.imread(img)\n",
        "        # processing the face to extract the landmark points (468 point) for each x,y,z\n",
        "        results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_face_landmarks != None: \n",
        "          # looping over the faces in the image\n",
        "          face = results.multi_face_landmarks[0]\n",
        "          for i,landmark in enumerate(face.landmark):\n",
        "            # nose is the index 1 in landmarks\n",
        "              x = landmark.x\n",
        "              y = landmark.y\n",
        "              if load_type == 'whole':\n",
        "                  \n",
        "                  data.setdefault(str(i)+'_x',[])\n",
        "                  data[str(i)+'_x'].append(x)\n",
        "                  data.setdefault(str(i)+'_y',[])\n",
        "                  data[str(i)+'_y'].append(y)\n",
        "              elif load_type == 'avg':\n",
        "                  data.setdefault(str(i),[])\n",
        "                  data[str(i)].append((x*0.7+y*0.3))\n",
        "              elif load_type == 'angle':\n",
        "                  dx = x - face.landmark[1].x\n",
        "                  dy = y - face.landmark[1].y\n",
        "                  theta = math.atan2(dy, np.sqrt(dx*dx))\n",
        "                  data.setdefault(str(i),[])\n",
        "                  data[str(i)].append(theta)\n",
        "              else: return None\n",
        "          mat_file = sio.loadmat('mat'.join(img.split('jpg')))\n",
        "          # extracting the labels 3 angels\n",
        "          pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
        "          pitch = pose_para[0]\n",
        "          yaw = pose_para[1]\n",
        "          roll = pose_para[2]\n",
        "          data.setdefault('pitch',[])\n",
        "          data['pitch'].append(pitch)\n",
        "          data.setdefault('yaw',[])\n",
        "          data['yaw'].append(yaw)   \n",
        "          data.setdefault('roll',[])\n",
        "          data['roll'].append(roll) \n",
        "  return data   "
      ],
      "metadata": {
        "id": "lA9SG1UbUuqn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load ALL X,y Data more approbriate for pitch model"
      ],
      "metadata": {
        "id": "pHXPuzUgUl8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.DataFrame(load_data('whole'))\n",
        "data_df.to_csv('pose_estimate.csv',index=False)"
      ],
      "metadata": {
        "id": "unbx8NvBUbxw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract face feature and instead of recording each x, y coordinate of the feature i will record average of them\n",
        "by understanding the problem and after alot of trials this average is the best for modeling yaw"
      ],
      "metadata": {
        "id": "zMPlAVoBpkXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_compressed_df = pd.DataFrame(load_data('avg'))\n",
        "data_compressed_df.to_csv('pose_estimate_avgComposed.csv',index=False)      "
      ],
      "metadata": {
        "id": "LV6UYv3zpCcM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract face feature and instead of recording each x, y coordinate of the feature i will record the ange between each point and the noise.\n",
        "\n",
        "this angle is the best calculation for roll"
      ],
      "metadata": {
        "id": "LeDG2ZVKzDxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_compArctan_df = pd.DataFrame(load_data('angle'))\n",
        "data_compArctan_df.to_csv('pose_estimate_arctanComposed.csv',index=False)    "
      ],
      "metadata": {
        "id": "KGnza9K9rIZK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-mZALwxa5xR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}